{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'seq2seq.trainer'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-65-04709c269f36>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mseq2seq\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mseq2seq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSupervisedTrainer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mseq2seq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mEncoderRNN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDecoderRNN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSeq2seq\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mseq2seq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPerplexity\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'seq2seq.trainer'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import scipy\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "import argparse\n",
    "import logging\n",
    "\n",
    "import torch\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "import torchtext\n",
    "\n",
    "import seq2seq\n",
    "from seq2seq.trainer import SupervisedTrainer\n",
    "from seq2seq.models import EncoderRNN, DecoderRNN, Seq2seq\n",
    "from seq2seq.loss import Perplexity\n",
    "from seq2seq.optim import Optimizer\n",
    "from seq2seq.dataset import SourceField, TargetField\n",
    "from seq2seq.evaluator import Predictor\n",
    "from seq2seq.util.checkpoint import Checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Chereji_2018_Occupancy_H3_CC_V64-chrI-1..230218.bedgraph\r\n",
      " generatetrain.m\r\n",
      " Hu_2014_nucleosome_over_avg_V64-chrI-1..230218.bedgraph\r\n",
      " PreNuc.m\r\n",
      " PreNuc.m~\r\n",
      "'Reference sequence-chrI-1..230218.fasta'\r\n",
      "'Reference sequence-chrI-1..230218.mm'\r\n"
     ]
    }
   ],
   "source": [
    "ls Nucleosom_data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "f = open('Nucleosom_data/Chereji_2018_Occupancy_H3_CC_V64-chrI-1..230218.bedgraph','r')\n",
    "f.readline()\n",
    "hist_occ_list = [[float(n) for n in l[1:].replace('\\n','').split('\\t') ] for l in f]\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "M = int(hist_occ_list[-1][1])\n",
    "hist_occ = np.zeros(M)\n",
    "for h in hist_occ_list:\n",
    "    hist_occ[int(h[0]):int(h[1])] = h[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(230218,)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hist_occ.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "230218"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class dataset_h5(Dataset):\n",
    "    def __init__(self,histone_file,fasta_file):\n",
    "        super(dataset_h5, self).__init__()\n",
    "        \n",
    "        #Loading FASTA file\n",
    "        f = open(fasta_file,'r')\n",
    "        f.readline() #Remove header\n",
    "        self.sequence=''\n",
    "        for l in f:\n",
    "            self.sequence  = self.sequence + l.replace('\\n','').lower()\n",
    "        \n",
    "        f = open(histone_file,'r')\n",
    "        f.readline() #Remove header\n",
    "        hist_occ_list = [[float(n) for n in l[1:].replace('\\n','').split('\\t') ] for l in f]\n",
    "        f.close()\n",
    "        \n",
    "        self.M = int(hist_occ_list[-1][1])\n",
    "        self.hist_occ = np.zeros(self.M)\n",
    "        for h in hist_occ_list:\n",
    "            self.hist_occ[int(h[0]):int(h[1])] = h[2]\n",
    "            \n",
    "        print('(Fasta len, Nucleosom len) =  ({0},{1})'.format(len(self.sequence),len(hist_occ)))\n",
    "    \n",
    "    def OHE(self,seq):\n",
    "        ohe = np.zeros((4,len(seq)))\n",
    "        for nuc in ['a','c','t','g']:\n",
    "            ohe[seq==nuc] = 1\n",
    "        \n",
    "        return ohe\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \n",
    "        return self.hist_occ[index],OHE(self.sequence[index])\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.M\n",
    "    \n",
    "fasta_file = 'Nucleosom_data/Reference sequence-chrI-1..230218.fasta'\n",
    "histone_file = 'Nucleosom_data/Chereji_2018_Occupancy_H3_CC_V64-chrI-1..230218.bedgraph'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare loss\n",
    "loss = Perplexity()\n",
    "if torch.cuda.is_available():\n",
    "    loss.cuda()\n",
    "\n",
    "# Initialize model\n",
    "hidden_size=128\n",
    "bidirectional = True\n",
    "\n",
    "encoder = EncoderRNN(len(src.vocab), max_len, hidden_size,\n",
    "                     bidirectional=bidirectional, variable_lengths=True)\n",
    "decoder = DecoderRNN(len(tgt.vocab), max_len, hidden_size * 2 if bidirectional else hidden_size,\n",
    "                     dropout_p=0.2, use_attention=True, bidirectional=bidirectional,\n",
    "                     eos_id=tgt.eos_id, sos_id=tgt.sos_id)\n",
    "\n",
    "seq2seq = Seq2seq(encoder, decoder)\n",
    "if torch.cuda.is_available():\n",
    "    seq2seq.cuda()\n",
    "\n",
    "for param in seq2seq.parameters():\n",
    "    param.data.uniform_(-0.08, 0.08)\n",
    "\n",
    "# Optimizer and learning rate scheduler can be customized by\n",
    "# explicitly constructing the objects and pass to the trainer.\n",
    "#\n",
    "# optimizer = Optimizer(torch.optim.Adam(seq2seq.parameters()), max_grad_norm=5)\n",
    "# scheduler = StepLR(optimizer.optimizer, 1)\n",
    "# optimizer.set_scheduler(scheduler)\n",
    "\n",
    "# train\n",
    "t = SupervisedTrainer(loss=loss, batch_size=32,\n",
    "                      checkpoint_every=50,\n",
    "                      print_every=10, expt_dir=opt.expt_dir)\n",
    "\n",
    "seq2seq = t.train(seq2seq, train,\n",
    "                  num_epochs=6, dev_data=dev,\n",
    "                  optimizer=optimizer,\n",
    "                  teacher_forcing_ratio=0.5,\n",
    "                  resume=opt.resume)\n",
    "\n",
    "predictor = Predictor(seq2seq, input_vocab, output_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "while_loop() got an unexpected keyword argument 'maximum_iterations'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-9301c7505c5f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mseq2seq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAttentionSeq2Seq\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAttentionSeq2Seq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_dim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_dim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_dim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdepth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'mse'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'rmsprop'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/GPU/lib/python3.6/site-packages/seq2seq-1.0.0-py3.6.egg/seq2seq/models.py\u001b[0m in \u001b[0;36mAttentionSeq2Seq\u001b[0;34m(output_dim, output_length, batch_input_shape, batch_size, input_shape, input_length, input_dim, hidden_dim, depth, bidirectional, unroll, stateful, dropout)\u001b[0m\n\u001b[1;32m    272\u001b[0m         \u001b[0mencoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward_layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    273\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 274\u001b[0;31m     \u001b[0mencoded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    275\u001b[0m     decoder = RecurrentSequential(decode=True, output_length=output_length,\n\u001b[1;32m    276\u001b[0m                                   unroll=unroll, stateful=stateful)\n",
      "\u001b[0;32m~/anaconda2/envs/GPU/lib/python3.6/site-packages/keras/layers/wrappers.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, initial_state, constants, **kwargs)\u001b[0m\n\u001b[1;32m    425\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    426\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minitial_state\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mconstants\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 427\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBidirectional\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    428\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m         \u001b[0;31m# Applies the same workaround as in `RNN.__call__`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/GPU/lib/python3.6/site-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, **kwargs)\u001b[0m\n\u001b[1;32m    455\u001b[0m             \u001b[0;31m# Actually call the layer,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m             \u001b[0;31m# collecting output(s), mask(s), and shape(s).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m             \u001b[0moutput_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprevious_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/GPU/lib/python3.6/site-packages/keras/layers/wrappers.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, mask, training, initial_state, constants)\u001b[0m\n\u001b[1;32m    520\u001b[0m                                              initial_state=backward_state, **kwargs)\n\u001b[1;32m    521\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 522\u001b[0;31m             \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward_layer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    523\u001b[0m             \u001b[0my_rev\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward_layer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    524\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/GPU/lib/python3.6/site-packages/recurrentshop-1.0.0-py3.6.egg/recurrentshop/engine.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, initial_state, initial_readout, ground_truth, mask, training)\u001b[0m\n\u001b[1;32m    623\u001b[0m                                                         \u001b[0mconstants\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconstants\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    624\u001b[0m                                                         \u001b[0munroll\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munroll\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 625\u001b[0;31m                                                         input_length=input_length)\n\u001b[0m\u001b[1;32m    626\u001b[0m         \u001b[0mstates\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    627\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/GPU/lib/python3.6/site-packages/recurrentshop-1.0.0-py3.6.egg/recurrentshop/backend/__init__.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'tensorflow'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mtensorflow_backend\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m         \u001b[0mrnn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;32melif\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'theano'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mtheano_backend\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/GPU/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36mrnn\u001b[0;34m(step_function, inputs, initial_states, go_backwards, mask, constants, unroll, input_length)\u001b[0m\n\u001b[1;32m   3009\u001b[0m             \u001b[0mparallel_iterations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3010\u001b[0m             \u001b[0mswap_memory\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3011\u001b[0;31m             maximum_iterations=input_length)\n\u001b[0m\u001b[1;32m   3012\u001b[0m         \u001b[0mlast_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfinal_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3013\u001b[0m         \u001b[0moutput_ta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfinal_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: while_loop() got an unexpected keyword argument 'maximum_iterations'"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "# Sample usage:\n",
    "#     # training\n",
    "#     python examples/sample.py --train_path $TRAIN_PATH --dev_path $DEV_PATH --expt_dir $EXPT_PATH\n",
    "#     # resuming from the latest checkpoint of the experiment\n",
    "#      python examples/sample.py --train_path $TRAIN_PATH --dev_path $DEV_PATH --expt_dir $EXPT_PATH --resume\n",
    "#      # resuming from a specific checkpoint\n",
    "#      python examples/sample.py --train_path $TRAIN_PATH --dev_path $DEV_PATH --expt_dir $EXPT_PATH --load_checkpoint $CHECKPOINT_DIR\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--train_path', action='store', dest='train_path',\n",
    "                    help='Path to train data')\n",
    "parser.add_argument('--dev_path', action='store', dest='dev_path',\n",
    "                    help='Path to dev data')\n",
    "parser.add_argument('--expt_dir', action='store', dest='expt_dir', default='./experiment',\n",
    "                    help='Path to experiment directory. If load_checkpoint is True, then path to checkpoint directory has to be provided')\n",
    "parser.add_argument('--load_checkpoint', action='store', dest='load_checkpoint',\n",
    "                    help='The name of the checkpoint to load, usually an encoded time string')\n",
    "parser.add_argument('--resume', action='store_true', dest='resume',\n",
    "                    default=False,\n",
    "                    help='Indicates if training has to be resumed from the latest checkpoint')\n",
    "parser.add_argument('--log-level', dest='log_level',\n",
    "                    default='info',\n",
    "                    help='Logging level.')\n",
    "\n",
    "opt = parser.parse_args()\n",
    "\n",
    "LOG_FORMAT = '%(asctime)s %(name)-12s %(levelname)-8s %(message)s'\n",
    "logging.basicConfig(format=LOG_FORMAT, level=getattr(logging, opt.log_level.upper()))\n",
    "logging.info(opt)\n",
    "\n",
    "if opt.load_checkpoint is not None:\n",
    "    logging.info(\"loading checkpoint from {}\".format(os.path.join(opt.expt_dir, Checkpoint.CHECKPOINT_DIR_NAME, opt.load_checkpoint)))\n",
    "    checkpoint_path = os.path.join(opt.expt_dir, Checkpoint.CHECKPOINT_DIR_NAME, opt.load_checkpoint)\n",
    "    checkpoint = Checkpoint.load(checkpoint_path)\n",
    "    seq2seq = checkpoint.model\n",
    "    input_vocab = checkpoint.input_vocab\n",
    "    output_vocab = checkpoint.output_vocab\n",
    "else:\n",
    "    # Prepare dataset\n",
    "    src = SourceField()\n",
    "    tgt = TargetField()\n",
    "    max_len = 50\n",
    "    def len_filter(example):\n",
    "        return len(example.src) <= max_len and len(example.tgt) <= max_len\n",
    "    train = torchtext.data.TabularDataset(\n",
    "        path=opt.train_path, format='tsv',\n",
    "        fields=[('src', src), ('tgt', tgt)],\n",
    "        filter_pred=len_filter\n",
    "    )\n",
    "    dev = torchtext.data.TabularDataset(\n",
    "        path=opt.dev_path, format='tsv',\n",
    "        fields=[('src', src), ('tgt', tgt)],\n",
    "        filter_pred=len_filter\n",
    "    )\n",
    "    src.build_vocab(train, max_size=50000)\n",
    "    tgt.build_vocab(train, max_size=50000)\n",
    "    input_vocab = src.vocab\n",
    "    output_vocab = tgt.vocab\n",
    "\n",
    "    # NOTE: If the source field name and the target field name\n",
    "    # are different from 'src' and 'tgt' respectively, they have\n",
    "    # to be set explicitly before any training or inference\n",
    "    # seq2seq.src_field_name = 'src'\n",
    "    # seq2seq.tgt_field_name = 'tgt'\n",
    "\n",
    "    # Prepare loss\n",
    "    weight = torch.ones(len(tgt.vocab))\n",
    "    pad = tgt.vocab.stoi[tgt.pad_token]\n",
    "    loss = Perplexity(weight, pad)\n",
    "    if torch.cuda.is_available():\n",
    "        loss.cuda()\n",
    "\n",
    "    seq2seq = None\n",
    "    optimizer = None\n",
    "    if not opt.resume:\n",
    "        # Initialize model\n",
    "        hidden_size=128\n",
    "        bidirectional = True\n",
    "        encoder = EncoderRNN(len(src.vocab), max_len, hidden_size,\n",
    "                             bidirectional=bidirectional, variable_lengths=True)\n",
    "        decoder = DecoderRNN(len(tgt.vocab), max_len, hidden_size * 2 if bidirectional else hidden_size,\n",
    "                             dropout_p=0.2, use_attention=True, bidirectional=bidirectional,\n",
    "                             eos_id=tgt.eos_id, sos_id=tgt.sos_id)\n",
    "        seq2seq = Seq2seq(encoder, decoder)\n",
    "        if torch.cuda.is_available():\n",
    "            seq2seq.cuda()\n",
    "\n",
    "        for param in seq2seq.parameters():\n",
    "            param.data.uniform_(-0.08, 0.08)\n",
    "\n",
    "        # Optimizer and learning rate scheduler can be customized by\n",
    "        # explicitly constructing the objects and pass to the trainer.\n",
    "        #\n",
    "        # optimizer = Optimizer(torch.optim.Adam(seq2seq.parameters()), max_grad_norm=5)\n",
    "        # scheduler = StepLR(optimizer.optimizer, 1)\n",
    "        # optimizer.set_scheduler(scheduler)\n",
    "\n",
    "    # train\n",
    "    t = SupervisedTrainer(loss=loss, batch_size=32,\n",
    "                          checkpoint_every=50,\n",
    "                          print_every=10, expt_dir=opt.expt_dir)\n",
    "\n",
    "    seq2seq = t.train(seq2seq, train,\n",
    "                      num_epochs=6, dev_data=dev,\n",
    "                      optimizer=optimizer,\n",
    "                      teacher_forcing_ratio=0.5,\n",
    "                      resume=opt.resume)\n",
    "\n",
    "predictor = Predictor(seq2seq, input_vocab, output_vocab)\n",
    "\n",
    "while True:\n",
    "    seq_str = raw_input(\"Type in a source sequence:\")\n",
    "    seq = seq_str.strip().split()\n",
    "    print(predictor.predict(seq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
